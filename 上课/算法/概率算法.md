# 概率算法
## 1 引论
### 期望事件与平均时间:
>+ 确定算法的平均执行时间:输入规模一定的所有输入实例是**等概率出现**时，算法的平均执行时间。
>+ 概率算法的期望执行时间:**反复解同一个输入**实例所花的平均执行时间。

因此对于概率算法有下面两种期望:
>+ 平均的期望时间：所有输入实例上平均的期望执行时间 
>+ 最坏的期望时间：最坏的输入实例上的期望执行时间

### 概率算法的特点
>+ 不可再现性:在同一个输入实例上，每次执行结果不尽相同.可能的原因有下面两种
>+ 分析困难:需要有概率论,统计学和数论知识.

### uniform函数
我们约定该函数随机,均匀,独立选取值其中:
>+ uniform(a,b):表示从$[a,b)$**实数区间**中挑选一个随机实数
>+ uniform(i..j):表示从$[a,b]$**整数区间**中挑选一个一个随机整数
>+ uniform(X)$\in$ X:表示从**非空集合X**中挑选一个X的元素

## 1.2 概率算法的分类:
### 基本特征(随机决策):
>+ 在同一实例上执行两次其结果(或过程)可能不同
>+ 在同一实例上执行两次的时间亦可能不太相同

### 分类:
大体上分成下面四类:
>+ Numerical(数字算法)
>+ Monte Carlo(蒙特卡洛)
>+ Las Vegas
>+ Sherwood

但很多人将所有概率算法(尤其是数字的概率算法) 称为Monte Carlo算法
**数字算法:**
随机性被最早用于求数字问题的近似解 
>+ 概率算法获得的答案一般是近似的，但通常算法执行的时间越长，精度就越高，误差就越小 
>+ 使用的理由:
>>+ 现实世界中的问题在原理上可能就不存在精确解,例如:实验数据本身就是近似的，一个无理数在计算机中只能近似地表示
>>+ 精确解存在但无法在可行的时间内求得 有时答案是以置信区间的形式给出的

**Monte Carlo算法 (MC算法)**
蒙特卡洛算法1945年由J. Von Neumann进行核武模拟提出的。它是以**概率和统计**的理论与方法为基础的一种**数值计算**方法，它是双重近似：
>+ 一是用概率模型模拟近似的数值计算
>+ 二是用伪随机数模拟真正的随机变量的样本。 

这里我们指的MC算法是： 若问题**只有1个正确的解**，而无近似解的可能时使用MC算法
**特点：** MC算法总是给出一个答案，但该答案未必正确，成功(即答案是正确的)的概率正比于算法执行的时间 
**缺点：** 一般不能有效地确定算法的答案是否正确

**Las Vegas算法 (LV算法)** 
LV算法**绝不返回错误的答案**。
特点：获得的**答案必定正确**，但有时它仍根本就找不到答案。 
和MC算法一样，成功的概率亦随算法执行时间增加而增加。无论输入何种实例，只要算法在该实例上运行足够的次数，则算法失败的概率就任意小。

**Sherwood算法**
**总是**给出正确的答案。 当某些确定算法解决一个特殊问题**平均的时间比最坏时间快得多**时，我们可以使用Sherwood算法来减少，甚至是消除好的和坏的实例之间的差别。

## 2.数字概率算法
### 定积分的概率算法1(hitormiss 算法)
若$I$为$\int_0^1 f(x)dx$的正确值,h时随机算法返回的值,当$n>I(1-I)/\epsilon^2\delta$时有:
$$Prob(|h-I|<\epsilon)\geq1-\delta$$
即当$n>I(1-I)/\epsilon^2\delta$时有算法的计算结果的绝对误差超过ε的概率不超过δ，因此我们根据给定ε和δ可以确定算法迭代的次数.
解决该问题时可是用切比雪夫不等式,将I看成期望

### 定积分的概率算法2(crude 算法)
在积分区间上随机均匀地产生点，求出这些点上的函数值的算术平均值，再乘以区间的宽度,其积分式可改写为：
$$\int_a^bf(x)dx=(b-a)\frac{1}{n}\sum_{i-1}^nf(x_i),a\leq x_i\leq b$$
算法流程(伪代码如下):
```c++
Crude (f, n, a, b) { 
    sum ← 0; 
        for i ← 1 to n do { 
            x ← uniform(a, b); 
            sum ← sum + f(x); 
            }
    return (b-a)sum/n;
}
```
对于给定的迭代次数n，Crude算法的方差不会大 于HitorMiss的方差。但不能说，Crude算法总是 优于HitorMiss。因为后者在给定的时间内能迭代 的次数更多。例如，计算π值时，Crude需计算 平方根，而用投镖算法darts时无需计算平方根。

### 定积分的确定算法(梯形算法)
将区间分为n-1个子区间，每个子区间内的长度为δ，类似的其积分式可改写为:
$$\int_a^bf(x)dx=\delta(f(a+\delta)+f(a+2\delta)+...+\frac{f(a)+f(b)}{2})$$
相当于将区间划分为n-2个区间,最后一个可能缺少的区间使用$\frac{f(a)+f(b)}{2}$代替
其算法流程可表示为:
```c++
Trapezoid (f, n, a, b) { // 假设 n ≥ 2 
    delta ← (b-a)/(n-1); 
    sum ← (f(a) + f(b))/2; 
    for x ← a+delta step delta to b – delta do 
        sum ← sum + f(x) 
    return sum × delta; 
}
```

一般的来说相同精度下梯形算法的迭代次数少于MC积分,但是有时候确定性积分算法求不出解,或者对于多重积分可能采样点过多导致无法计算

### 2.3 概率计数
#### 求集合的势
设X是具有n个元素的集合，我们有回放地随机， 均匀和独立地从X中选取元素，设k是出现第1次重 复之前所选出的元素数目，则当n足够大时，k的期 望值趋近为$\beta \sqrt{n}$，这里:
$$\beta = \sqrt{\pi/2}=1.253$$
因此可以得到估计|X|的概率算法为:
$$\beta \sqrt x=\sqrt{n\pi/2}=k\\
\,\\
n=\frac{2k^2}{\pi}$$
其算法流程可写为:
```c++
SetCount (X) { 
    k ← 0; S ← Ф; 
    a ← uniform(X); 
    do { 
        k++; 
        S ← S U{a}; 
        a ← uniform(X); 
    } while (a ∉ S);
    return 2k2/π;
}
```
该算法期望的时间/空间复杂度为$\theta(\sqrt n)$,因为$k=\theta(\sqrt n)$

#### 多重集合不同对象数目估计
设U是单词序列的集合，设参数m稍大于lgM，可令$m=5+\lceil{lg M}\rceil $,设h为一个$U\to{0,1}^m$的散列函数,定义$\pi(y,b)$ b为0或者1,该函数表示第y中第一次出现b(0/1)的位置,其算法流程为:
```c++
WordCount () { y[1..m+1] ← 0; // 初始化 
    for 磁带上每个单词x do { //顺序读磁带 
        i ← π(h(x), 1); // x的散列值中等于1的最小位置，表示x是以00..01打头的 
        y[i] ← 1; // 将该位置置为1 
    }
    return π(y, 0); // 返回y中等于0的最小位置 
}
```
**上界估计:**
如果散列函数值足够平均,则可以通过返回的$\pi(y,0)$进行单词个数的估计,假设有m个单词,其第返回的位置为k,则其一个粗略的上界为$2^k$
**下界估计:**
同理,类似的可以得到对应的一个下界为$2^{k-2}$
**其他分析:**
磁带上互不相同的单词数目为：$2^{k-2}～2^k$ 
实际上，算法WordCount估计的n应等于2k/1.54703
性能：时间O(N)，空间：O(lgN)

## 3 sherwood算法
对于一个确定算法,其解决大小为n的实例平均执行时间可以表示为:
$$
\bar{t}_A(n)=\sum_{x\in X_n}t_A(x)/|X_n|
$$
但是仍可能存在对于某个大小为n的数据使得其所需计算时间远大于平均执行时间

对于一个概率算法,其平均执行时间可以写为:
$$
t_B(x)=\bar{t}_A(n)+s(n)
$$
其中s(n)为随机化取得均匀性所付出的代价,通常情况下远小于确定性算法计算时间

### 3.2 随机的预处理
将一个算法改成sherwood算法的一般算法为:
>+ ① 将被解的实例变换到一个随机实例。// 预处理
>+ ② 用确定算法解此随机实例，得到一个解。 
>+ ③ 将此解变换为对原实例的解。 // 后处理

对于解决某问题的函数$f:X\to Y$,随机的预处理可以由一对函数构成:
$$
u:X_{old}\times A \to X_{New}\\
v:A\times Y_{New} \to Y_{old}
$$
$$
\begin{aligned}
&u:a \to [(g^r\, mod \, p)*a]\, mod\,p,(r\in [0,p-2])\\
&v:(r+x)\, mod (p-1)\to x
\end{aligned}
$$
u,v满足下面三个性质:
>+ 原实例x可通过随机抽样变换成另一个实例
>+ 对y的解可变换为对原实例x的解
>+ 函数u,v在最坏的情况均能有效计算


## 4.Las Vegas 算法
**Las Vegas算法特点:**
>+ 可能不时地要冒着找不到解的风险，算法要么返回正确的解， 要么随机决策导致一个僵局。 
>+ 若算法陷入僵局，则使用同一实例运行同一算法，有独立的 机会求出解。 
>+ 成功的概率随着执行时间的增加而增加
>+ Las Vegas算法一般能获得更有效率的算法,甚至有时对于每个实例皆如此,但是Las Vegas的时间上界可能不存在

**算法的一般形式:**
|数学符号|含义|
|---|---|
|$LV(x,y,success):$|x是输入的实例，y是返回 的参数，success是布尔值，true表示成功，false 表示失败|
|$p(x)$|对于实例x，算法成功的概率|
|$s(x)$|算法成功时的期望时间|
|$e(x)$|算法失败时的期望时间|

一个正确的算法要求对于每个实例,$p(x)>0$,对于算法的一种更好限制为:
$$
\exist 常数 \delta>0,\, p(x)\geq \delta
$$

对于Las Vegas算法的期望时间$t(x)$:
$$
t(x) = s(x) + \frac{1-p(x)}{p(x)}e(x)
$$
为了提高整体性能$t(x)$,如果减少失败时间$e(x)$,有时可能会导致成果概率降低$p(x)$,因此需要对其进行折中.    


### 模p平方根
定义:设p为奇质数对于$x\in [1,n-1]$,如果存在y使得:
$$
x\equiv y^2 (mod\,\,p)
$$
则称x是模p意义下的二次剩余,使用$(p-y)^2$以及设$a^2,b^2$w为形如$^2a=k_1p+r$可以证明,对于相同x,有且仅有2个y使得满足原式(定理1,2可得),且这两整数满足$y_2=p-y_1$,且能进一步推倒对于$[1,p-1]$仅有一半的元素x使得x为二次剩余

定理4:对于$\forall x \in [1,n-1],p$为任意偶数,则有$x^{(p-1)/2}\equiv \pm 1(mod\,\,p)$,由费马小定理可得(费马小定理:$x^{p-1}\equiv 1(mod\,\, p)$),并且x为模p的二次剩余当且仅当$x^{(p-1)/2}\equiv 1$

假设已知x为模p意义下的二次剩余,求其平方根:
>+ 1. 当p%4=3时,平方根为$\pm x^{(p+1)/4}$
>+ 2. 当p%4=1时,平方根可以由下面LasVegas算法得到

LasVegas算法:
设$\sqrt x$为较小的平方根,设$y_1=a+\sqrt m,y_2=a-\sqrt m,a\in N^+$
>+ 1. 随机选取2个a,计算对应$y_1^{(p-1)/2},y_2^{(p-1)/2}$
>+ 2. 如果$y_1^{(p-1)/2}+y_2^{(p-1)/2} \equiv 0(mod \,\, p)$则进入下一步,否则回到步骤1
>+ 3. 此时不妨设$y_1^{(p-1)/2}\equiv 1(mod\,\, p),y_2^{(p-1)/2}\equiv -1(mod \,\, p)$则我们有:
$$
y_1^{(p-1)/2}+y_2^{(p-1)/2}\equiv 0(mod\,\, p)\\
y_1^{(p-1)/2}-y_2^{(p-1)/2}\equiv 2(mod\,\, p)
$$
>+ 4. 不妨设$y_1^{(p-1)/2}=c+d_1\sqrt x,y_2^{(p-1)/2}=c-d_2\sqrt x$那么我们可以得到下面的关系:
$$
2c \equiv 0 (mod \,\, p)\\
d\sqrt x \equiv1(mod\,\, p)
$$
>+ 此时d已知,我们只需要找到满足$d\sqrt x \equiv1(mod\,\, p)$的一个数,则该数即为方程的一个解,这个数可以枚举验证,也可使用拓展欧几里得求解

### 整数的因数分解:
合数的二次剩余(模数为合数),如果该合数n可以表示为$n=pq$,其中p,q表示两个不同的素数,则对于模n的二次剩余恰有4个不同的平方根

#### Dixon因数分解算法
基本思想:找两个与n互素的整数a和b，使$a^2\equiv b^2(mod \,\, p)$,且$a\neq \pm b$,则两式相减有$(a-b)*(a+b)\equiv 0(mod \,\, n)$那么我们就可以找到$gcd((a+b),n)$即为n的一个非平凡因数(a-b)可能为1
那么对于满足条件的a,b我们进行下面的方式进行构造:
首先定义这样一个概念(k-平滑):若一个整数x的所有素因子均在前k个素数之中，则x称为k-平滑的。
>+ 选定k(k越大后面数字越好找,但是因数分解代价会变大,否则反之)
>+ 随机选取k+1个$x_i$,使得满足$y_i=x_i^2 mod\,\, p$,且$y_i$是k-平滑的
>+ 对所有y进行因数分解,并记录对应因数次数
>+ 在k+1组y进行组合找到其中一个组合使得$y_iy_j...y_k=p_1^{2m_1}p^{2m_2}...p_k^{2m_3}$此时我们令$b=\sqrt{p_1^{2m_1}p^{2m_2}...p_k^{2m_3}}=p_1^{m_1}p^{m_2}...p_k^{m_3}$
>+ 我们令a为对应的x项乘积即:$a=x_ix_j...x_k$我们可以简单验证$a^2\equiv b^2 mod\,\, p$
>+ 此时我们找到对应的a,b即可进行因数推断



## Monte Carlo算法
### 基础概念
**性质:** 
Monte Carlo算法偶然会犯错，但它无论对何实例均能以高概率找到正确解。当算法出错时，没有警告信息。
**相关定义:**
>+ Def1：设p是一个实数，且1/2< p <1，若一个MC算法 以不小于p的概率返回一个正确的解，则该MC算法称 为p-正确，算法的优势（advantage）是 p-1/2. (正确的概率至少大于一半)
>+ Def2：若一个MC算法对同一实例**决不给出两个不同的正确解**，则该算法称是**相容**的（consistent）或一致的。

**基本思想:**
为了增加一个一致的、p-正确算法成功的概率，只需多次调用同一算法，然后选择**出现次数最多**的解。

#### 有偏算法:
**偏真/偏假算法:** 为简单起见，设MC(x)是解某个判定问 题，对任何x，若当MC(x)返回true时解总是正确的，仅当它返回false时才有可能产生错误的解，则称此算法为偏真的(true-biased)。
同理如果MC算法返回false时一定错误,而当返回true时可能正确
**偏y0算法:** 将解决的问题进行扩展,对于问题求解的结果,如果返回的是y0,则一定正确,如果返回非y0时可能出错,并且我们定义当返回非y0时以p概率正确
**定理:** 对于有偏的算法,设其成功概率为p,重复次数为k,那么执行k次后得到正确结果的概率为$1-(1-p)^k$

#### 如何确定给定精度的重复次数?
符号解释:
>+ $\varepsilon:$为算法的优势(即$\varepsilon=p-0.5$)
>+ $\delta:$为给定的容许错误的概率(即算法以$1-\delta$的概率成功)

定理:设2个正实数之和$ε+\delta<0.5$，MC(x)是一个$一致的$、 $(0.5+ε)-correct$的蒙特卡洛算法,设:
$$
C_{\varepsilon}=\frac{-2}{lg(1-4\varepsilon^2)}
$$
如果调用原先算法至少k次:
$$
k=\lceil C_{\varepsilon}lg(1/\delta) \rceil
$$
我们可以得到一个与原先算法有相同实例的一致的($1-\delta$)概率正确的新MC算法


### 5.1 主元素问题:
**定义:** 给定一个数组,如果存在某个元素出现次数大于数组容量的一半时,我们称该元素为主元素
我们定义一个主元素判定问题:给定数组**是否存在**主元素?
算法流程:
```c++
maj(T) { //测试随机元素 是否为T的主元素 
    i←uniform(1..n); 
    x←T [ i ] ; 
    k←0; 
    for j←1 to n do 
        if T [ j ]=x then 
            k←k+1; 
    return (k>n/2);     
}
```
基本思想,随机挑选一个数组中的元素,判断该元素是否为主元素,显然这个算法对于原问题来说是一个**偏真**的算法
一个显然的结论是,对于该算法执行k次后正确的概率为:$1-0.5^k$

### 5.3 素数测定
**前置知识(费马小定理):**
若n为素数,则$\forall a \in [1,n-1]$有$a^{n-1}\,mod\,\,n =1$,对其取逆否得到下面一个等价的判定命题:
若n和a为整数,若$\exist a \in [1,n-1]$使得$a^{n-1}mod\,\, n \neq 1$则n不是素数.

那么根据上述命题我们可以构造下面的一个偏假算法:
```c++
Fermat(n) { 
    a ←uniform(1..n-1); 
    if power(a,n-1)%n == 1 then 
        return true; //未必正确，n未必为素数 
    else 
        return false；//正确，n一定是合数 
}
```
#### 伪素数与素性伪证据
**伪素数:** 如果一个合数n满足$a^{n-1}\, mod\,\,n=1$,则我们称其为伪素数,并且我们称其为以a为底的伪素数,对于前10亿个自然数中,以2为底的素数仅有5000+个,从概率上来描述,错误的概率仅为0.00011
**伪证据**:则为对于给定n,对于随机选取的a使得$a^{n-1}\, mod\,\,n=1$成立的证据
**强伪素数:** n是一个大于4的奇整数，s和t是使得$n-1=2^st$的正整数， 其中t为奇数，设B(n)是如下定义的整数集合满足下面条件任一即可：
>+ $a^t\,mod\,\, n =1$
>+ $\exist i\in [0,s-1]$使得$a^{2it}\,mod \,\, n= n-1$
若n为素数,其对所有$a\in [2,n-2]$均有$a\in B(n)$
若n为合数,如果存在$a\in [2,n-2]$有$a\in B(n)$,则称n为**强伪素数**,而对应的a为n素性的**强伪证据**
与费马小定理类似的,我们可以转化其逆否命题来构造一个偏假算法
```c++
Btest(a，n){//n为奇数， 返回 。即返回真说明n是强伪素数或素数 
    s←0； t ←n-1； // t开始为偶数 
    repeat 
        s++；t ← t÷2； 
    until t mod 2 = 1； //n-1=2st ， t为奇数 
    x ←at mod n； 
    if x=1 or x=n-1 then return true；//满足①or②
    for i ←1 to s-1 do{ //验证 
        x ← x2 mod n； 
        if x=n-1 then return true； //满足②
    }
    return false； 
}
```
对于合数,其强伪证据个数不会超过$\frac{n}{4}$,因此最差情况下Btest是一个$75\%-correct$正确的算法,对于其组成的k次MC算法,其正确率为$1-(\frac{1}{4})^k$