# DistDGL

## 1.Abstract
### Motivation：
>GNN相关应用广泛，且通常节点/边数目很多

### 系统整体概要：

>首先这个系统是基于Deep Graph Library（DGL）的分布式GNN计算框架，对于计算任务采用owner-compute rule进行计算分解，同时该系统采用同步训练（synchronous training approach），允许自我中心网络来形成mini-batches，为了减少不必要的网络通信，会储存部分非本地的节点，并使用高质量，轻量级的图分区算法减少分布式系统的依赖

### Result：
>线性时间加速，且不影响精度（可能是跟minibatch串行相比）,在一个16台服务器组成的计算集群上，13s能完成一次包含10亿点以及30亿边的epoch

## 2.Introduction
### 区别
>首先图数据是一种典型的非欧几里得数据，不能跟训练样本中存在极大的依赖属性，因此对GNN采取mini-batch训练于传统的深度学习有很大的不同，设计取样函数时需要尽可能削减点集之间的依赖（dependency），同时本文再三强调，GNN跟计算机视觉以及自然语言处理不同的地方在于通常情况下GNN的瓶颈在于为了获取邻居节点信息以及通过通信减少顶点依赖所带来的通信开销，因此不能照搬其他领域的框架，要尽可能减少网络之间由于依赖导致的通信代价。

### 技术细节
>1. 本文主要采取的计算方法为同步随机梯度下降（synchronized stochastic gradient descent 简称SGD）并取得了较好的结果，但是使用该方法需要注意的是需要生成的mini-batches 需要大致上平衡生成数据集的点数量以及边数量（不过本文也交代了通常网络情况是比较复杂的，因此生成这样非常平衡的训练样本通常也是比较困难的）
>2. 为了解决上述表明的减少通信开销，本文采取了除了生成的mini-batch除了包含必须的目标节点，还额外保存部分与目标节点邻接的非本地节点，来减少跨服务器的通信，以及复制光环节点（halo nodes），同时本文也采用METIS来进行图分区减少跨服务器的数据交换。
>3. 本文的系统为了进一步保证负载均衡采用了：1.多约束分区；2.两层工作负载划分

### Result
在4台服务器为计算集群的系统上本文的分布式系统较Euler速度提升2.2倍，时间提升主要来自于5倍的高效特征数据拷贝，同时在不降低精度的同时实现了线性的时间提升，能在16台服务器组成的计算集群中解决1亿个点30亿条边的gnn问题

## 3.BACKGROUND
>由于之前提及的顶点以依赖问题，故mini-batch采点时需要注意子图在原图中的数据依赖性，文章中提到了一种经典的采点策略，大致分为3步：
1）随机的取N个顶点作为目标训练顶点集
2）对于每个选取的顶点，找至多K个邻接节点加入到训练集合
3）对选中的目标顶点，搜集邻接点的信息作为其representation

## 4.DISTDGL SYSTEM DESIGN


